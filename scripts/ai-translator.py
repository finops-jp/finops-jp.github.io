#!/usr/bin/env python3
"""
AI Translator for FinOps Foundation Content

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€GitHub Models (Claude 3.5 Sonnet)ã‚’ä½¿ç”¨ã—ã¦
FinOps Foundationã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¾ã™ã€‚
"""

import os
import json
import hashlib
import re
import argparse
from pathlib import Path
from typing import Dict, Optional
import requests
from bs4 import BeautifulSoup
import html2text
from datetime import datetime

# è¨­å®š
FINOPS_BASE_URL = "https://www.finops.org"
DOCS_DIR = Path("docs")
STATUS_FILE = Path(".translation-status.json")
GLOSSARY_FILE = Path("scripts/glossary.json")

# GitHub Models APIè¨­å®š
GITHUB_MODELS_API = "https://models.inference.ai.azure.com/chat/completions"
MODEL_NAME = "gpt-4o"  # GitHub Modelsã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«


def load_glossary() -> Dict[str, str]:
    """å°‚é–€ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã¿"""
    if GLOSSARY_FILE.exists():
        with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def get_page_content(url: str) -> tuple[str, str]:
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
        title = soup.find('h1')
        title_text = title.get_text(strip=True) if title else ""
        
        # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
        main_content = soup.find('main') or soup.find('article') or soup.body
        
        if main_content:
            # HTMLã‚’Markdownã«å¤‰æ›
            h = html2text.HTML2Text()
            h.ignore_links = False
            h.ignore_images = False
            h.ignore_emphasis = False
            h.body_width = 0  # è¡Œã®æŠ˜ã‚Šè¿”ã—ã‚’ç„¡åŠ¹åŒ–
            
            markdown = h.handle(str(main_content))
            return markdown, title_text
        
        return "", title_text
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return "", ""


def translate_with_github_models(text: str, glossary: Dict[str, str], title: str = "") -> str:
    """GitHub Models APIã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³"""
    
    github_token = os.getenv('GITHUB_TOKEN')
    if not github_token:
        raise ValueError("GITHUB_TOKEN environment variable is required")
    
    # å°‚é–€ç”¨èªè¾æ›¸ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
    glossary_text = "\n".join([f"- {en}: {ja}" for en, ja in glossary.items()])
    
    prompt = f"""ã‚ãªãŸã¯FinOps(ã‚¯ãƒ©ã‚¦ãƒ‰è²¡å‹™ç®¡ç†)ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è‹±èªã®FinOpsæŠ€è¡“æ–‡æ›¸ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

# ç¿»è¨³ãƒ«ãƒ¼ãƒ«

1. **å°‚é–€ç”¨èª**: ä»¥ä¸‹ã®ç”¨èªã¯å¿…ãšã“ã®ç¿»è¨³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
{glossary_text}

2. **Markdownæ§‹é€ **: å…ƒã®Markdownæ§‹é€ ã‚’å®Œå…¨ã«ä¿æŒã—ã¦ãã ã•ã„
   - è¦‹å‡ºã—ãƒ¬ãƒ™ãƒ«(#, ##, ###ãªã©)
   - ãƒªã‚¹ãƒˆ(-, *, 1.ãªã©)
   - ãƒªãƒ³ã‚¯([text](url))
   - å¼·èª¿(**bold**, *italic*)
   - ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯

3. **ç¿»è¨³å“è³ª**:
   - è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èª
   - æŠ€è¡“æ–‡æ›¸ã¨ã—ã¦æ­£ç¢º
   - æ–‡è„ˆã‚’ç†è§£ã—ãŸç¿»è¨³

4. **å›ºæœ‰åè©**: ä»¥ä¸‹ã¯ãã®ã¾ã¾è‹±èªã§æ®‹ã™
   - FinOps
   - AWS, Azure, GCP ãªã©ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å
   - è£½å“åã€ã‚µãƒ¼ãƒ“ã‚¹å

# ç¿»è¨³å¯¾è±¡

{text}

# å‡ºåŠ›å½¢å¼

ç¿»è¨³ã•ã‚ŒãŸMarkdownãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„æ³¨é‡ˆã¯ä¸è¦ã§ã™ã€‚"""

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {github_token}"
    }
    
    payload = {
        "messages": [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯FinOpsæŠ€è¡“æ–‡æ›¸ã®ç¿»è¨³å°‚é–€å®¶ã§ã™ã€‚æ­£ç¢ºã§è‡ªç„¶ãªæ—¥æœ¬èªç¿»è¨³ã‚’æä¾›ã—ã¾ã™ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "model": MODEL_NAME,
        "temperature": 0.3,
        "max_tokens": 4000
    }
    
    try:
        response = requests.post(
            GITHUB_MODELS_API,
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()
        
        result = response.json()
        translated_text = result['choices'][0]['message']['content']
        
        return translated_text.strip()
    
    except Exception as e:
        print(f"Translation error: {e}")
        if hasattr(e, 'response'):
            print(f"Response: {e.response.text}")
        raise


def create_translated_document(
    source_url: str,
    translated_content: str,
    title: str
) -> str:
    """ç¿»è¨³ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ—¢å­˜ã®å½¢å¼ã§ä½œæˆ"""
    
    # frontmatterã‚’ä½œæˆ
    frontmatter = f"""---
title: {title}
---

[è‹±èªç‰ˆ]: {source_url}

:::warning[ãƒ‰ãƒ©ãƒ•ãƒˆã®ãƒšãƒ¼ã‚¸]

ç¿»è¨³ã¯æ©Ÿæ¢°ç¿»è¨³ã«ã‚ˆã‚Šæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
ç¿»è¨³å†…å®¹ã¨[è‹±èªç‰ˆ]ã®é–“ã§é½Ÿé½¬ã€ä¸ä¸€è‡´ã€çŸ›ç›¾ãŒã‚ã‚‹å ´åˆã¯[è‹±èªç‰ˆ]ã‚’å„ªå…ˆã—ã¾ã™ã€‚

:::

"""
    
    return frontmatter + translated_content


def get_output_path(source_url: str) -> Path:
    """ã‚½ãƒ¼ã‚¹URLã‹ã‚‰å‡ºåŠ›ãƒ‘ã‚¹ã‚’æ±ºå®š"""
    # URLã‹ã‚‰ãƒ‘ã‚¹ã‚’æŠ½å‡º
    path = source_url.replace(FINOPS_BASE_URL, '').strip('/')
    
    # docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã«é…ç½®
    if path.endswith('/'):
        output_path = DOCS_DIR / path / "index.md"
    else:
        output_path = DOCS_DIR / f"{path}.md"
    
    return output_path


def update_translation_status(source_url: str, output_path: Path, content_hash: str):
    """ç¿»è¨³çŠ¶æ…‹ã‚’æ›´æ–°"""
    status = {}
    if STATUS_FILE.exists():
        with open(STATUS_FILE, 'r', encoding='utf-8') as f:
            status = json.load(f)
    
    rel_path = str(output_path.relative_to(DOCS_DIR))
    
    status[rel_path] = {
        "translated": True,
        "source_url": source_url,
        "source_hash": content_hash,
        "translated_date": datetime.now().isoformat(),
        "last_checked": datetime.now().isoformat(),
        "needs_update": False
    }
    
    with open(STATUS_FILE, 'w', encoding='utf-8') as f:
        json.dump(status, f, indent=2, ensure_ascii=False)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='Translate FinOps content to Japanese')
    parser.add_argument('--url', required=True, help='Source URL to translate')
    parser.add_argument('--output', help='Output file path (optional)')
    
    args = parser.parse_args()
    
    source_url = args.url
    
    print(f"ğŸŒ ã‚½ãƒ¼ã‚¹URL: {source_url}")
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
    print("ğŸ“¥ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ä¸­...")
    content, title = get_page_content(source_url)
    
    if not content:
        print("âŒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return 1
    
    print(f"ğŸ“„ ã‚¿ã‚¤ãƒˆãƒ«: {title}")
    print(f"ğŸ“ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚º: {len(content)} æ–‡å­—")
    
    # å°‚é–€ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã¿
    print("ğŸ“š å°‚é–€ç”¨èªè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    glossary = load_glossary()
    print(f"   {len(glossary)}ä»¶ã®ç”¨èªã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # ç¿»è¨³
    print("ğŸ¤– AIç¿»è¨³ä¸­ (GitHub Models)...")
    translated_content = translate_with_github_models(content, glossary, title)
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
    print("ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆä¸­...")
    document = create_translated_document(source_url, translated_content, title)
    
    # å‡ºåŠ›ãƒ‘ã‚¹ã‚’æ±ºå®š
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = get_output_path(source_url)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    print(f"ğŸ’¾ ä¿å­˜ä¸­: {output_path}")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(document)
    
    # ç¿»è¨³çŠ¶æ…‹ã‚’æ›´æ–°
    content_hash = hashlib.sha256(content.encode()).hexdigest()
    update_translation_status(source_url, output_path, content_hash)
    
    print(f"\nâœ… ç¿»è¨³å®Œäº†!")
    print(f"   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    
    return 0


if __name__ == "__main__":
    exit(main())
